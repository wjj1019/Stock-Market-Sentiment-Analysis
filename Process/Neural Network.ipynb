{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/woojaejo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "from urllib.request import urlopen, Request\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate, Dropout, Flatten, Bidirectional\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from tensorflow import keras\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Library import \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed.csv')\n",
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = {1: 'Positive', -1:'Negative'}\n",
    "df['Sentiment'] = df['Sentiment'].map(dmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = pd.get_dummies(df['Sentiment'])\n",
    "# y = df['Sentiment'].map(lambda x: 1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction - Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words\n",
    "cv = CountVectorizer(ngram_range=(1,1))\n",
    "bow_X = cv.fit_transform(X).toarray()\n",
    "# Tfidf\n",
    "tf = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_X = tf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the \n",
    "test = [i.split() for i in df['Text']]\n",
    "model = Word2Vec(sentences=test, vector_size=300, window=3, min_count=1, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['user'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('short', 0.9996002912521362),\n",
       " ('good', 0.9995472431182861),\n",
       " ('aap', 0.9995437860488892),\n",
       " ('stock', 0.9995434284210205),\n",
       " ('today', 0.9995408654212952),\n",
       " ('one', 0.9995338320732117),\n",
       " ('big', 0.9995330572128296),\n",
       " ('still', 0.9995279908180237),\n",
       " ('see', 0.9995168447494507),\n",
       " ('stocks', 0.9995134472846985)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('trade', topn=10)  # get other similar words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "pretrained = KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz',binary=True,limit=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Parameters\n",
    "max_features = 5000 #Input dimensions\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing and Padding\n",
    "tokenizer = Tokenizer(num_words = max_features, oov_token='OOV')\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences(X)\n",
    "padded = pad_sequences(sequence, maxlen=20)\n",
    "\n",
    "#Word Dictionary\n",
    "word_index = tokenizer.word_index\n",
    "#Vocabulary Size +1 (for NN input)\n",
    "vocab = len(word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5118, 20)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3582, 20) (3582, 2)\n",
      "(768, 20) (768, 2)\n",
      "(768, 20) (768, 2)\n"
     ]
    }
   ],
   "source": [
    "#Train Test Validation Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded, y, test_size=0.3, random_state=42)    \n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 3,986\n",
      "Trainable params: 3,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Multilayered Perceptron\n",
    "nn = Sequential()\n",
    "nn.add(Input(shape=(20,)))\n",
    "nn.add(Dense(64, activation = 'relu',))\n",
    "nn.add(Dense(32, activation = 'relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(16, activation = 'relu'))\n",
    "nn.add(Dense(2, activation = 'softmax'))\n",
    "print(nn.summary())\n",
    "\n",
    "nn.compile(loss = 'categorical_crossentropy', optimizer = 'RMSprop', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 7ms/step - loss: 63.6148 - accuracy: 0.5002 - val_loss: 21.2935 - val_accuracy: 0.6151\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 24.6459 - accuracy: 0.5442 - val_loss: 13.5406 - val_accuracy: 0.6430\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 14.9456 - accuracy: 0.5564 - val_loss: 8.5550 - val_accuracy: 0.6123\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10.0267 - accuracy: 0.5508 - val_loss: 5.7502 - val_accuracy: 0.5802\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 7.0669 - accuracy: 0.5599 - val_loss: 3.8053 - val_accuracy: 0.5495\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4.2034 - accuracy: 0.5508 - val_loss: 2.3808 - val_accuracy: 0.4756\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6847 - accuracy: 0.5445 - val_loss: 1.2659 - val_accuracy: 0.6081\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4969 - accuracy: 0.5703 - val_loss: 0.9117 - val_accuracy: 0.4128\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.2343 - accuracy: 0.5689 - val_loss: 0.8929 - val_accuracy: 0.3766\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.5801 - val_loss: 0.8215 - val_accuracy: 0.3821\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.8325 - accuracy: 0.6066 - val_loss: 0.7561 - val_accuracy: 0.6471\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7835 - accuracy: 0.5976 - val_loss: 0.6754 - val_accuracy: 0.6430\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7761 - accuracy: 0.6042 - val_loss: 0.6594 - val_accuracy: 0.6457\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.6084 - val_loss: 0.6902 - val_accuracy: 0.6444\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.6066 - val_loss: 0.6744 - val_accuracy: 0.6444\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.6115 - val_loss: 0.6581 - val_accuracy: 0.6444\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.6206 - val_loss: 0.6810 - val_accuracy: 0.6444\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6237 - val_loss: 0.6647 - val_accuracy: 0.6444\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6826 - accuracy: 0.6216 - val_loss: 0.6789 - val_accuracy: 0.6220\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6798 - accuracy: 0.6234 - val_loss: 0.6798 - val_accuracy: 0.6430\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.6286 - val_loss: 0.7074 - val_accuracy: 0.6430\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.6251 - val_loss: 0.6525 - val_accuracy: 0.6444\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.6293 - val_loss: 0.6538 - val_accuracy: 0.6444\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6307 - val_loss: 0.6580 - val_accuracy: 0.6430\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6258 - val_loss: 0.6549 - val_accuracy: 0.6444\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6797 - accuracy: 0.6279 - val_loss: 0.6582 - val_accuracy: 0.6444\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6304 - val_loss: 0.6530 - val_accuracy: 0.6444\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.6290 - val_loss: 0.6557 - val_accuracy: 0.6444\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.6286 - val_loss: 0.6546 - val_accuracy: 0.6430\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.6321 - val_loss: 0.6508 - val_accuracy: 0.6444\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.6300 - val_loss: 0.6517 - val_accuracy: 0.6457\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6728 - accuracy: 0.6297 - val_loss: 0.6498 - val_accuracy: 0.6444\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6314 - val_loss: 0.6462 - val_accuracy: 0.6444\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6300 - val_loss: 0.6498 - val_accuracy: 0.6444\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6690 - accuracy: 0.6321 - val_loss: 0.6539 - val_accuracy: 0.6430\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6571 - accuracy: 0.6314 - val_loss: 0.6503 - val_accuracy: 0.6444\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.6304 - val_loss: 0.6583 - val_accuracy: 0.6444\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6335 - val_loss: 0.6509 - val_accuracy: 0.6444\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6297 - val_loss: 0.6507 - val_accuracy: 0.6444\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6304 - val_loss: 0.6548 - val_accuracy: 0.6444\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6304 - val_loss: 0.6495 - val_accuracy: 0.6457\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6293 - val_loss: 0.6535 - val_accuracy: 0.6457\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.6325 - val_loss: 0.6645 - val_accuracy: 0.6444\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6335 - val_loss: 0.6723 - val_accuracy: 0.6444\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.6349 - val_loss: 0.6573 - val_accuracy: 0.6444\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.6328 - val_loss: 0.6621 - val_accuracy: 0.6444\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6339 - val_loss: 0.6535 - val_accuracy: 0.6444\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6318 - val_loss: 0.6567 - val_accuracy: 0.6430\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6318 - val_loss: 0.6629 - val_accuracy: 0.6416\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6399 - accuracy: 0.6342 - val_loss: 0.6625 - val_accuracy: 0.6430\n"
     ]
    }
   ],
   "source": [
    "history = nn.fit(X_train, y_train, epochs = 50, batch_size = batch_size, verbose =1,\n",
    "      validation_data=(X_valid, y_valid), validation_split= 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems like the local optimal was found along the way to global minimum and the gap between train and validation loss increases as epochs increase (sign of overfitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 20, 100)           833000    \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                128064    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 963,210\n",
      "Trainable params: 963,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Embedding Layer creation\n",
    "nn = Sequential()\n",
    "nn.add(Embedding(input_dim = vocab, output_dim = 100, input_length = 20 ))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "nn.add(Dropout(0.4))\n",
    "nn.add(Dense(32, activation = 'relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(2, activation = 'softmax'))\n",
    "print(rnn.summary())\n",
    "\n",
    "nn.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 1s 14ms/step - loss: 1.3159 - accuracy: 0.6293 - val_loss: 0.8914 - val_accuracy: 0.6263\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.7517 - accuracy: 0.6334 - val_loss: 0.6778 - val_accuracy: 0.6263\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.6088 - accuracy: 0.6868 - val_loss: 0.6203 - val_accuracy: 0.6810\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.4562 - accuracy: 0.8169 - val_loss: 0.6029 - val_accuracy: 0.7357\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.3098 - accuracy: 0.9213 - val_loss: 0.6513 - val_accuracy: 0.7161\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.2006 - accuracy: 0.9712 - val_loss: 0.6964 - val_accuracy: 0.7266\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.1454 - accuracy: 0.9860 - val_loss: 0.7327 - val_accuracy: 0.7253\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.1117 - accuracy: 0.9913 - val_loss: 0.8008 - val_accuracy: 0.7253\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0798 - accuracy: 0.9955 - val_loss: 0.8047 - val_accuracy: 0.7266\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0681 - accuracy: 0.9975 - val_loss: 0.8219 - val_accuracy: 0.7318\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0559 - accuracy: 0.9978 - val_loss: 0.8452 - val_accuracy: 0.7318\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0495 - accuracy: 0.9983 - val_loss: 0.8712 - val_accuracy: 0.7292\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0452 - accuracy: 0.9983 - val_loss: 0.8776 - val_accuracy: 0.7253\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0452 - accuracy: 0.9972 - val_loss: 0.9848 - val_accuracy: 0.7266\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0410 - accuracy: 0.9972 - val_loss: 0.9262 - val_accuracy: 0.7201\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0348 - accuracy: 0.9983 - val_loss: 0.9784 - val_accuracy: 0.7214\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 0.0331 - accuracy: 0.9980 - val_loss: 0.9650 - val_accuracy: 0.7227\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0290 - accuracy: 0.9989 - val_loss: 0.9549 - val_accuracy: 0.7214\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9980 - val_loss: 0.9885 - val_accuracy: 0.7122\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9980 - val_loss: 1.0576 - val_accuracy: 0.7279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85307e8f10>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, epochs = 20, batch_size = batch_size, verbose = 1,\n",
    "       validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sign of overfitting, accuracy of trainset increases overtime and loss decreases, validation set loss increases at certain point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the maximum token counts \n",
    "def get_max_length(df):\n",
    "\n",
    "    max_length = 0\n",
    "    for row in df['Text']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will be the padding length \n",
    "get_max_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix (dimension, vocab_size, word2vec, word_index):\n",
    "    \n",
    "    embedding_dim = dimension # Embedding Dimensions\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim)) #Initializing Embedding Matrix (Weight Matrix for Embedding Layer)\n",
    "    embedding_vector = 0 #Initialization of vector for each word \n",
    "\n",
    "    #Iterate through word_index obtained from Keras\n",
    "    for word, index in word_index.items():\n",
    "        try:\n",
    "            embedding_vector = word2vec[word] #Extract 300dim vector from pretrained word Embedding\n",
    "        except:\n",
    "            pass #if the word within the word_index not present, leave it as 0 vector\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector #Place embedding vector into embedding matrix\n",
    "    print('Embedding Matrix Shape:', embedding_matrix.shape)\n",
    "    \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Matrix Shape: (8330, 300)\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding = embedding_matrix(300, vocab_size = vocab, word2vec = pretrained, word_index = word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3582, 23) (3582, 2)\n",
      "(768, 23) (768, 2)\n",
      "(768, 23) (768, 2)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequence = tokenizer.texts_to_sequences(X)\n",
    "padding = pad_sequences(sequence, maxlen = 23)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(padding, y, test_size=0.3, random_state=42)    \n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size = 0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 23, 300)           2499000   \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 6900)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 64)                441664    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,942,810\n",
      "Trainable params: 443,810\n",
      "Non-trainable params: 2,499,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Pretrained Embedding - Multilayered Perceptron\n",
    "nn = Sequential()\n",
    "nn.add(Embedding(input_dim = vocab, output_dim = 300, input_length = 23, \n",
    "                embeddings_initializer = keras.initializers.Constant(pretrained_embedding),\n",
    "                trainable = False))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(64, activation = 'relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(32, activation = 'relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(2, activation = 'sigmoid'))\n",
    "print(nn.summary())\n",
    "\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "28/28 [==============================] - 1s 9ms/step - loss: 0.6656 - accuracy: 0.6131 - val_loss: 0.6407 - val_accuracy: 0.6380\n",
      "Epoch 2/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.6706 - val_loss: 0.6251 - val_accuracy: 0.6562\n",
      "Epoch 3/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.5733 - accuracy: 0.7111 - val_loss: 0.6193 - val_accuracy: 0.6602\n",
      "Epoch 4/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7644 - val_loss: 0.6343 - val_accuracy: 0.6562\n",
      "Epoch 5/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8157 - val_loss: 0.6852 - val_accuracy: 0.6549\n",
      "Epoch 6/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8529 - val_loss: 0.7358 - val_accuracy: 0.6562\n",
      "Epoch 7/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.3057 - accuracy: 0.8878 - val_loss: 0.7935 - val_accuracy: 0.6602\n",
      "Epoch 8/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2583 - accuracy: 0.9068 - val_loss: 0.8576 - val_accuracy: 0.6576\n",
      "Epoch 9/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2108 - accuracy: 0.9305 - val_loss: 0.9732 - val_accuracy: 0.6549\n",
      "Epoch 10/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9444 - val_loss: 1.0158 - val_accuracy: 0.6471\n",
      "Epoch 11/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9598 - val_loss: 1.0332 - val_accuracy: 0.6471\n",
      "Epoch 12/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1111 - accuracy: 0.9696 - val_loss: 1.2124 - val_accuracy: 0.6406\n",
      "Epoch 13/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.1001 - accuracy: 0.9696 - val_loss: 1.2669 - val_accuracy: 0.6471\n",
      "Epoch 14/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9774 - val_loss: 1.2547 - val_accuracy: 0.6562\n",
      "Epoch 15/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9793 - val_loss: 1.4225 - val_accuracy: 0.6523\n",
      "Epoch 16/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9768 - val_loss: 1.4038 - val_accuracy: 0.6458\n",
      "Epoch 17/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9855 - val_loss: 1.4940 - val_accuracy: 0.6523\n",
      "Epoch 18/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9880 - val_loss: 1.5594 - val_accuracy: 0.6549\n",
      "Epoch 19/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9877 - val_loss: 1.5899 - val_accuracy: 0.6523\n",
      "Epoch 20/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9869 - val_loss: 1.6548 - val_accuracy: 0.6536\n",
      "Epoch 21/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 1.6115 - val_accuracy: 0.6471\n",
      "Epoch 22/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9891 - val_loss: 1.7397 - val_accuracy: 0.6602\n",
      "Epoch 23/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 1.7206 - val_accuracy: 0.6419\n",
      "Epoch 24/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0313 - accuracy: 0.9905 - val_loss: 1.8500 - val_accuracy: 0.6289\n",
      "Epoch 25/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9897 - val_loss: 1.7645 - val_accuracy: 0.6341\n",
      "Epoch 26/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9916 - val_loss: 1.8590 - val_accuracy: 0.6419\n",
      "Epoch 27/30\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9886 - val_loss: 1.8591 - val_accuracy: 0.6471\n",
      "Epoch 28/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 1.8182 - val_accuracy: 0.6406\n",
      "Epoch 29/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 1.8599 - val_accuracy: 0.6445\n",
      "Epoch 30/30\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 1.9327 - val_accuracy: 0.6432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85322f6190>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_train, y_train, epochs = 30, batch_size = batch_size, verbose = 1, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Loss and Train Loss has a large gap in between -> Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.keras.optimizers.Adam(lr=0.0003, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 23, 300)           2499000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 23, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 258)               576888    \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 2)                 518       \n",
      "=================================================================\n",
      "Total params: 3,076,406\n",
      "Trainable params: 577,406\n",
      "Non-trainable params: 2,499,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# RNN -LSTM\n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(input_dim = vocab, output_dim = 300, input_length = 23, \n",
    "                embeddings_initializer = keras.initializers.Constant(pretrained_embedding),\n",
    "                trainable = False))\n",
    "\n",
    "rnn.add(SpatialDropout1D(0.5))\n",
    "rnn.add(LSTM(258, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "rnn.add(Dense(2,activation='softmax'))\n",
    "rnn.compile(loss = 'categorical_crossentropy', optimizer=optimizer ,metrics = ['accuracy'])\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 6s 156ms/step - loss: 0.6558 - accuracy: 0.6245 - val_loss: 0.6423 - val_accuracy: 0.6315\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 4s 147ms/step - loss: 0.6275 - accuracy: 0.6597 - val_loss: 0.6289 - val_accuracy: 0.6484\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.6111 - accuracy: 0.6711 - val_loss: 0.6212 - val_accuracy: 0.6576\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.6057 - accuracy: 0.6790 - val_loss: 0.6168 - val_accuracy: 0.6615\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 4s 146ms/step - loss: 0.5952 - accuracy: 0.6915 - val_loss: 0.6117 - val_accuracy: 0.6628\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.5911 - accuracy: 0.6834 - val_loss: 0.6099 - val_accuracy: 0.6680\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 4s 157ms/step - loss: 0.5935 - accuracy: 0.6946 - val_loss: 0.6094 - val_accuracy: 0.6693\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.5837 - accuracy: 0.6965 - val_loss: 0.6081 - val_accuracy: 0.6745\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 4s 152ms/step - loss: 0.5815 - accuracy: 0.7004 - val_loss: 0.6050 - val_accuracy: 0.6719\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 4s 150ms/step - loss: 0.5677 - accuracy: 0.7094 - val_loss: 0.6011 - val_accuracy: 0.6836\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.5703 - accuracy: 0.7138 - val_loss: 0.5989 - val_accuracy: 0.6836\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 0.5694 - accuracy: 0.7130 - val_loss: 0.5994 - val_accuracy: 0.6836\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 4s 157ms/step - loss: 0.5578 - accuracy: 0.7183 - val_loss: 0.5991 - val_accuracy: 0.6797\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 0.5593 - accuracy: 0.7183 - val_loss: 0.5994 - val_accuracy: 0.6836\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 5s 177ms/step - loss: 0.5499 - accuracy: 0.7217 - val_loss: 0.6066 - val_accuracy: 0.6875\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 4s 151ms/step - loss: 0.5594 - accuracy: 0.7152 - val_loss: 0.6118 - val_accuracy: 0.6836\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 4s 150ms/step - loss: 0.5507 - accuracy: 0.7217 - val_loss: 0.6009 - val_accuracy: 0.6732\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 4s 152ms/step - loss: 0.5499 - accuracy: 0.7261 - val_loss: 0.6036 - val_accuracy: 0.6771\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 4s 151ms/step - loss: 0.5518 - accuracy: 0.7219 - val_loss: 0.6131 - val_accuracy: 0.6836\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 4s 154ms/step - loss: 0.5469 - accuracy: 0.7292 - val_loss: 0.6005 - val_accuracy: 0.6797\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X_train, y_train, epochs = 20, batch_size = batch_size, verbose = 1, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation loss is fluctuating at certain point, it might reached local minimum, regularization required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_64 (Embedding)     (None, 23, 300)           2499000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_43 (Spatia (None, 23, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_60 (LSTM)               (None, 258)               576888    \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 32)                8288      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 3,084,242\n",
      "Trainable params: 585,242\n",
      "Non-trainable params: 2,499,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Adding Regularization L1 L2 \n",
    "rnn = Sequential()\n",
    "rnn.add(Embedding(input_dim = vocab, output_dim = 300, input_length = 23, \n",
    "                embeddings_initializer = keras.initializers.Constant(pretrained_embedding),\n",
    "                trainable = False))\n",
    "\n",
    "rnn.add(SpatialDropout1D(0.5))\n",
    "rnn.add(LSTM(258, dropout=0.2, recurrent_dropout=0.2))\n",
    "rnn.add(Dense(32, activation = 'relu',kernel_regularizer=regularizers.l1_l2(l1 = 0.01, l2 = 0.01)))\n",
    "rnn.add(Dropout(0.5))\n",
    "rnn.add(Dense(2,activation='softmax'))\n",
    "rnn.compile(loss = 'categorical_crossentropy', optimizer='adam' ,metrics = ['accuracy'])\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 6s 168ms/step - loss: 5.9741 - accuracy: 0.6150 - val_loss: 4.8065 - val_accuracy: 0.6263\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 3.9123 - accuracy: 0.6474 - val_loss: 3.0373 - val_accuracy: 0.6576\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 4s 148ms/step - loss: 2.4031 - accuracy: 0.6575 - val_loss: 1.8028 - val_accuracy: 0.6576\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 5s 164ms/step - loss: 1.4067 - accuracy: 0.6675 - val_loss: 1.0492 - val_accuracy: 0.6562\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 5s 173ms/step - loss: 0.8596 - accuracy: 0.6669 - val_loss: 0.7185 - val_accuracy: 0.6471\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 4s 145ms/step - loss: 0.6837 - accuracy: 0.6365 - val_loss: 0.6728 - val_accuracy: 0.6289\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 4s 147ms/step - loss: 0.6610 - accuracy: 0.6488 - val_loss: 0.6630 - val_accuracy: 0.6510\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 4s 147ms/step - loss: 0.6574 - accuracy: 0.6572 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 4s 149ms/step - loss: 0.6561 - accuracy: 0.6664 - val_loss: 0.6630 - val_accuracy: 0.6510\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 5s 170ms/step - loss: 0.6501 - accuracy: 0.6829 - val_loss: 0.6576 - val_accuracy: 0.6719\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 4s 157ms/step - loss: 0.6409 - accuracy: 0.6910 - val_loss: 0.6524 - val_accuracy: 0.6732\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 0.6377 - accuracy: 0.6915 - val_loss: 0.6508 - val_accuracy: 0.6719\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 5s 178ms/step - loss: 0.6350 - accuracy: 0.7041 - val_loss: 0.6534 - val_accuracy: 0.6771\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 5s 180ms/step - loss: 0.6275 - accuracy: 0.7046 - val_loss: 0.6608 - val_accuracy: 0.6875\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 6s 217ms/step - loss: 0.6309 - accuracy: 0.7133 - val_loss: 0.6573 - val_accuracy: 0.6732\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 6s 208ms/step - loss: 0.6141 - accuracy: 0.7094 - val_loss: 0.6457 - val_accuracy: 0.6758\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 5s 168ms/step - loss: 0.6198 - accuracy: 0.7133 - val_loss: 0.6547 - val_accuracy: 0.6706\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 4s 158ms/step - loss: 0.6203 - accuracy: 0.7141 - val_loss: 0.6467 - val_accuracy: 0.6914\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 5s 181ms/step - loss: 0.6134 - accuracy: 0.7205 - val_loss: 0.6491 - val_accuracy: 0.6823\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 4s 156ms/step - loss: 0.6112 - accuracy: 0.7091 - val_loss: 0.6400 - val_accuracy: 0.6888\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X_train, y_train, epochs = 20, batch_size = batch_size, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot accuracy Curve\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot Loss Curve\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loss0.6169412136077881, model accuracy 0.7057291865348816\n"
     ]
    }
   ],
   "source": [
    "print('model loss {}, model accuracy {}'.format(rnn.evaluate(X_test, y_test, verbose =0)[0], rnn.evaluate(X_test, y_test, verbose = 0)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the learning curve, the validation and training loss converges and accuracy increases as more iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_82\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_61 (Embedding)     (None, 23, 300)           2499000   \n",
      "_________________________________________________________________\n",
      "bidirectional_43 (Bidirectio (None, 23, 64)            85248     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_42 (Spatia (None, 23, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_44 (Bidirectio (None, 32)                10368     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,596,858\n",
      "Trainable params: 97,858\n",
      "Non-trainable params: 2,499,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional RNN \n",
    "brnn = Sequential()\n",
    "brnn.add(Embedding(input_dim = vocab, output_dim = 300, input_length = 23, \n",
    "                embeddings_initializer = keras.initializers.Constant(pretrained_embedding),\n",
    "                trainable = False))\n",
    "\n",
    "brnn.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "brnn.add(SpatialDropout1D(0.4))\n",
    "brnn.add(Bidirectional(LSTM(16)))\n",
    "brnn.add(Dropout(0.4))\n",
    "brnn.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(l1 = 0.01, l2 = 0.01)))\n",
    "brnn.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "print(brnn.summary())\n",
    "brnn.compile(loss = 'binary_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 7s 110ms/step - loss: 3.3558 - accuracy: 0.6340 - val_loss: 3.0002 - val_accuracy: 0.6419\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 2.7149 - accuracy: 0.6329 - val_loss: 2.4162 - val_accuracy: 0.6419\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 2.1682 - accuracy: 0.6329 - val_loss: 1.9151 - val_accuracy: 0.6432\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 1.7073 - accuracy: 0.6614 - val_loss: 1.5161 - val_accuracy: 0.6966\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.3482 - accuracy: 0.7102 - val_loss: 1.2072 - val_accuracy: 0.6914\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 1.0587 - accuracy: 0.7278 - val_loss: 0.9865 - val_accuracy: 0.6927\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.8547 - accuracy: 0.7379 - val_loss: 0.8296 - val_accuracy: 0.6927\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 1s 35ms/step - loss: 0.7042 - accuracy: 0.7501 - val_loss: 0.7080 - val_accuracy: 0.6797\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.6118 - accuracy: 0.7686 - val_loss: 0.6595 - val_accuracy: 0.6628\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5837 - accuracy: 0.7677 - val_loss: 0.6608 - val_accuracy: 0.6953\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5600 - accuracy: 0.7912 - val_loss: 0.6488 - val_accuracy: 0.6680\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5404 - accuracy: 0.7976 - val_loss: 0.6561 - val_accuracy: 0.6641\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5279 - accuracy: 0.8015 - val_loss: 0.6659 - val_accuracy: 0.6706\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5095 - accuracy: 0.8157 - val_loss: 0.6584 - val_accuracy: 0.6836\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.5047 - accuracy: 0.8143 - val_loss: 0.6703 - val_accuracy: 0.6953\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4991 - accuracy: 0.8180 - val_loss: 0.6579 - val_accuracy: 0.6758\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 1s 37ms/step - loss: 0.4841 - accuracy: 0.8258 - val_loss: 0.6686 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4814 - accuracy: 0.8258 - val_loss: 0.6941 - val_accuracy: 0.6562\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 1s 36ms/step - loss: 0.4746 - accuracy: 0.8294 - val_loss: 0.6680 - val_accuracy: 0.6979\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 1s 39ms/step - loss: 0.4687 - accuracy: 0.8305 - val_loss: 0.6884 - val_accuracy: 0.6862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84eea606a0>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brnn.fit(X_train, y_train, epochs = 20, batch_size = batch_size, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_63 (Embedding)     (None, 23, 300)           2499000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 32)            76832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 2,578,424\n",
      "Trainable params: 79,424\n",
      "Non-trainable params: 2,499,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Convolutional Layer\n",
    "cnn = Sequential()\n",
    "cnn.add(Embedding(input_dim = vocab, output_dim = 300, input_length = 23, \n",
    "                embeddings_initializer = keras.initializers.Constant(pretrained_embedding),\n",
    "                trainable = False))\n",
    "\n",
    "cnn.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "cnn.add(MaxPooling1D(pool_size=2))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(10, activation='relu'))\n",
    "cnn.add(Dense(2, activation='sigmoid'))\n",
    "print(cnn.summary())\n",
    "\n",
    "cnn.compile(loss = 'categorical_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "28/28 [==============================] - 1s 15ms/step - loss: 0.6566 - accuracy: 0.6265 - val_loss: 0.6274 - val_accuracy: 0.6471\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.5838 - accuracy: 0.6935 - val_loss: 0.6079 - val_accuracy: 0.6758\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.4894 - accuracy: 0.7775 - val_loss: 0.6008 - val_accuracy: 0.7057\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.8565 - val_loss: 0.6151 - val_accuracy: 0.7018\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.9249 - val_loss: 0.6697 - val_accuracy: 0.6862\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.1557 - accuracy: 0.9637 - val_loss: 0.7409 - val_accuracy: 0.7083\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0945 - accuracy: 0.9821 - val_loss: 0.8139 - val_accuracy: 0.6797\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0583 - accuracy: 0.9933 - val_loss: 0.8832 - val_accuracy: 0.6901\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0372 - accuracy: 0.9961 - val_loss: 0.9522 - val_accuracy: 0.6966\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0245 - accuracy: 0.9989 - val_loss: 1.0064 - val_accuracy: 0.6797\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0186 - accuracy: 0.9997 - val_loss: 1.0668 - val_accuracy: 0.6810\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9997 - val_loss: 1.1107 - val_accuracy: 0.6888\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0119 - accuracy: 0.9997 - val_loss: 1.1561 - val_accuracy: 0.6888\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.6784\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0092 - accuracy: 0.9994 - val_loss: 1.2223 - val_accuracy: 0.6914\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 1.2545 - val_accuracy: 0.6758\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0052 - accuracy: 0.9997 - val_loss: 1.2958 - val_accuracy: 0.6901\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 1.3017 - val_accuracy: 0.6888\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 1.3265 - val_accuracy: 0.6862\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 0.9997 - val_loss: 1.3588 - val_accuracy: 0.6901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85163bbcd0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs = 20, batch_size = batch_size, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- It seems like many of the models are overfitting due to the environment of neural network, we have tried many regularization techniques such as Dropout layers (Default and Spatial) L1 and L2 regularization, alternating learning rate and scheduling learning rate (Exponential Decay at certain point). \n",
    "- Performance of LSTM worked the best and with the least model complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
